{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Prediccion de Imagenes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Cargar Datos\n",
    "\n",
    "Cargamos la base de datos caltech-101 desde un directorio local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se encuentran las im√°genes\n",
    "data_dir = 'D:\\\\U\\\\7. Septimo\\\\RI\\\\ir24a\\\\week14\\\\caltech-101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las im√°genes desde el directorio\n",
    "\n",
    "# Se usa para cargar las im√°genes de training\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2, \n",
    "    subset=\"training\", \n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Se usa para cargar las im√°genes de test\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2, \n",
    "    subset=\"validation\", \n",
    "    seed=123,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el total de im√°genes en tu dataset es ùëã, entonces:\n",
    "- El conjunto de entrenamiento tendr√° 0.8ùëã im√°genes.\n",
    "- El conjunto de prueba/validaci√≥n tendr√° 0.2ùëã im√°genes.\n",
    "\n",
    "Por lo que especificamente se tendria: \n",
    "Total de im√°genes \n",
    "ùëã ‚âà 7316 + 1828 = 9144\n",
    "- Conjunto de entrenamiento: 0.8 √ó 9144 ‚âà 7316 im√°genes.\n",
    "- Conjunto de prueba/validaci√≥n: 0.2 √ó 9144 ‚âà 1828 im√°genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las rutas de las im√°genes\n",
    "def get_image_paths(directory, split):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('jpg', 'jpeg', 'png')):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    # Dividir las rutas en conjunto de entrenamiento y prueba\n",
    "    num_images = len(image_paths)\n",
    "    split_idx = int(num_images * split)\n",
    "    return image_paths[:split_idx], image_paths[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las rutas de las im√°genes para los datasets\n",
    "train_image_paths, test_image_paths = get_image_paths(data_dir, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preprocesamineto de las imagenes\n",
    "\n",
    "Usamos las librerias VGG16 y tensorflow.keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el n√∫mero de clases\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar las im√°genes \n",
    "def preprocess_image(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Aplicar la funci√≥n de preprocesamiento a los datasets\n",
    "train_dataset = train_dataset.map(preprocess_image)\n",
    "test_dataset = test_dataset.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Extraccion de Caracteristicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo ResNet50 con pesos preentrenados\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Crear un nuevo modelo que produzca los mapas de caracter√≠sticas\n",
    "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para extraer caracter√≠sticas junto con rutas de archivos\n",
    "def extract_features(dataset, image_paths):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch, image_path in zip(dataset, image_paths):\n",
    "        images, lbls = batch\n",
    "        feature_maps = model.predict(images)\n",
    "        features.append(feature_maps)\n",
    "        labels.append(lbls.numpy())\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer caracter√≠sticas para los conjuntos de datos de entrenamiento y prueba\n",
    "train_features, train_labels, train_image_paths = extract_features(train_dataset, train_image_paths)\n",
    "test_features, test_labels, test_image_paths = extract_features(test_dataset, test_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Indexacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un √≠ndice usando k-NN\n",
    "knn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree').fit(train_features.reshape(train_features.shape[0], -1))\n",
    "\n",
    "# Guardar el √≠ndice y las rutas de las im√°genes\n",
    "index_data = {\n",
    "    'knn': knn,\n",
    "    'train_image_paths': train_image_paths\n",
    "}\n",
    "\n",
    "with open('knn_index1.pkl', 'wb') as f:\n",
    "    pickle.dump(index_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Motor de B√∫squeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para buscar im√°genes similares\n",
    "def search_image(query_image, knn_index, train_image_paths, k=5):\n",
    "    query_features = model.predict(query_image[np.newaxis, ...])\n",
    "    distances, indices = knn_index.kneighbors(query_features.reshape(1, -1), n_neighbors=k)\n",
    "    similar_image_paths = [train_image_paths[i] for i in indices[0]]\n",
    "    return similar_image_paths, distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para cargar y preprocesar una imagen que no sea parte del dataset\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = tf.cast(img_array, tf.float32) / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la imagen que no es parte del dataset\n",
    "query_img_path = 'D:\\\\U\\\\7. Septimo\\\\RI\\\\imagenes\\\\Cat_November_2010-1a.jpg'  # Cambia esta ruta a la de tu imagen de consulta\n",
    "query_image = load_and_preprocess_image(query_img_path)\n",
    "\n",
    "# Mostrar la imagen de consulta\n",
    "plt.imshow(query_image.numpy())\n",
    "plt.title('Imagen de consulta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar la b√∫squeda\n",
    "with open('knn_index2.pkl', 'rb') as f:\n",
    "    index_data = pickle.load(f)\n",
    "\n",
    "similar_image_paths, distances = search_image(query_image, index_data['knn'], index_data['train_image_paths'])\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"√çndices de las im√°genes m√°s similares:\", similar_image_paths)\n",
    "print(\"Distancias a las im√°genes m√°s similares:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las im√°genes m√°s similares\n",
    "for path, dist in zip(similar_image_paths, distances):\n",
    "    similar_image = image.load_img(path)\n",
    "    plt.imshow(similar_image)\n",
    "    plt.title(f'Ruta: {path}, Distance: {dist:.2f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Evaluaci√≥n del Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el sistema (sin F1-Score)\n",
    "def evaluate_system(test_features, test_labels, knn_index):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in range(len(test_features)):\n",
    "        query_features = test_features[i]\n",
    "        distances, indices = knn_index.kneighbors(query_features.reshape(1, -1), n_neighbors=1)\n",
    "        y_true.append(test_labels[i])\n",
    "        y_pred.append(train_labels[indices[0][0]])\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = evaluate_system(test_features, test_labels, index_data['knn'])\n",
    "print(f\"Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo utilizado para la extracci√≥n de caracter√≠sticas en un archivo .h5\n",
    "model.save('modelo2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
